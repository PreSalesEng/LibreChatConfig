version: 1.1.6

cache: true

registration:
  allowedDomains: ["${ALLOWED_DOMAIN_PRIMARY}", "${ALLOWED_DOMAIN_SECONDARY}"]

endpoints:
  custom:
    # deepseek
    # https://platform.deepseek.com/api_keys
    # Model list: https://platform.deepseek.com/api-docs/pricing
    - name: "deepseek"
      apiKey: "${DEEPSEEK_API_KEY}"
      baseURL: "https://api.deepseek.com"
      models:
        default: [
          "deepseek-chat",
          "deepseek-coder",
          "deepseek-reasoner",
          ]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      summarize: false
      summaryModel: "deepseek-chat"
      modelDisplayLabel: "DeepSeek"
    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "gemma2-9b-it",
          "gemma-7b-it",
          "llama-3.1-8b-instant",
          "llama3-groq-70b-8192-tool-use-preview",
          "llama3-groq-8b-8192-tool-use-preview",
          "llama-3.1-70b-versatile",
          "llama-3.1-70b-specdec",
          "llama-3.1-8b-instant",
          "llama-3.2-1b-preview",
          "llama-3.2-3b-preview",
          "llama-3.2-11b-vision-preview",
          "llama-3.2-90b-vision-preview",
          "llama3-70b-8192",
          "llama3-8b-8192",
          "mixtral-8x7b-32768",
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"
    # Mistral AI API
    # Model list: https://docs.mistral.ai/getting-started/models/
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models: 
        default: [
          "mistral-large-latest",
          "pixtral-large-latest",
          "ministral-3b-latest",
          "ministral-8b-latest",
          "mistral-small-latest",
          "codestral-latest",
          "pixtral-12b-2409",
          "open-mistral-nemo",
          "open-codestral-mamba",
          "open-mistral-7b",
          "open-mixtral-8x7b",
          "open-mixtral-8x22b"
          ]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: false
      summaryModel: "mistral-tiny"
      forcePrompt: false
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # NVIDIA         
    # https://build.nvidia.com/explore/discover
    - name: "Nvidia"
      apiKey: "${NVIDIA_API_KEY}"
      baseURL: "https://integrate.api.nvidia.com/v1/"
      models:
        default: [
          "nvidia/llama-3.1-nemotron-51b-instruct",
          "nvidia/llama-3.1-nemotron-70b-instruct",
          "nvidia/nemotron-mini-4b-instruct",
          "nvidia/nemotron-4-340b-instruct",
          ]
        fetch: false
      titleConvo: true
      titleModel: "nvidia/nemotron-mini-4b-instruct"
      modelDisplayLabel: "Nvidia"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/refs/heads/main/icons/nvidia.png"
    # Preplexity
    # Model list: https://docs.perplexity.ai/docs/model-cards
    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default: [
          "llama-3.1-sonar-small-128k-chat",
          "llama-3.1-sonar-small-128k-online",
          "llama-3.1-sonar-large-128k-chat",
          "llama-3.1-sonar-large-128k-online",
          "llama-3.1-sonar-huge-128k-online",
          "llama-3.1-8b-instruct",
          "llama-3.1-70b-instruct"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      summarize: false
      summaryModel: "llama-3.1-sonar-small-128k-chat"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"